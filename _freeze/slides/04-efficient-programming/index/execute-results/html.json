{
  "hash": "630d8e679c1d0a2085dadfaedabe8c5a",
  "result": {
    "markdown": "---\ntitle: Efficient Programming\nsubtitle: Advanced R\nauthor: \n  - name: Heather Turner and Ella Kaye\n  - name: Department of Statistics, University of Warwick\ntitle-slide-attributes:\n  data-background-color: \"#552D62\"\ndate: 2023-06-19\ndate-format: long\nformat: \n  warwickpres-revealjs:\n    execute:\n      echo: true\n      code-overflow: wrap\n---\n\n\n## Overview\n\n- Memory management\n- Benchmarking\n- Improving run time\n- Parallelisation\n- Outlook to package development\n\n# Memory management {.inverse}\n\n## Overview\n\nObjects created in R are stored in memory. This has the advantage that\nobjects can be accessed faster, but R slows down as the memory fills up.\nCreating objects also takes time. \n\nTherefore:\n\n::: {.incremental}\n- Re-use temporary variables. The allocated storage will be re-used if\nthe vector has the same length.\n- Save results for re-use, e.g. index variables\n- Don't save intermediate results unnecessarily -- compute on-the-fly\n- Remove large objects when no longer needed (with `rm()`)\n:::\n\n## Basic data structures\n\nTry to use the simplest data structure for your purpose\n\n - matrices vs. data frames \n - character or integer vectors vs. factors\n - logical or integer vectors vs. numeric vectors\n - unnamed objects vs. named objects\n\n. . .\n\nIt is especially important to use low-level structures for computation\n\nYou can create richer objects as a final step before returning to the user.\n\n::: {.notes}\nL for integer\n:::\n\n## Big Data\n\nModern computers have enough RAM to work with millions of records \nusing standard functions.\n\nSome packages to work more efficiently with big data:\n\n - **data.table** faster operations on data frames; read/write \nlarge CSVs\n - **dplyr** + **dbplyr** processing of data in databases.\n - **arrow** read/write large CSVs or binary files e.g. Parquet; processing larger-than-memory data with **dplyr** commands.\n - **bigmemory**, **biganalytics** faster matrix operations,\ngeneralized linear models, kmeans\n\n::: {.notes}\nN.B. sparse matrices not as efficient as you might expect for general programming, may need big data for it to be important.\n\nParallelisation can also help, see later\n:::\n\n## Growing Objects\n\nAdding to an object in a loop\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nres <- NULL\nfor (i in 1:5000) res <- c(res, 1)\n```\n:::\n\n   \nmay force a copy to be made at each iteration, with each copy stored until the\nloop has completed. \n\n. . .\n\nIt is **far better** to create an object of the necessary size first  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nres <- numeric(5000)\nfor (i in seq_along(res)) res[i] <- 1\n```\n:::\n\n\nTo initialise a list we can use\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nres <- vector(mode = \"list\", length = 100)\n```\n:::\n\n\n## Copy-on-Change\n\nR usually copies an object to make changes to it.\n\n`tracemem` can be used to trace copies of an object\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nz <- NULL\nfor (i in 1:3){ z <- c(z,1); print(tracemem(z)) }\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"<0x159494e98>\"\n[1] \"<0x11d8bb188>\"\n[1] \"<0x159356ee8>\"\n```\n:::\n:::\n\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nz <- numeric(2); print(tracemem(z))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"<0x11a698788>\"\n```\n:::\n:::\n\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfor (i in 1:2){z[i] <- i;print(tracemem(z))}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntracemem[0x11a698788 -> 0x11a620648]: eval eval eval_with_user_handlers withVisible withCallingHandlers handle timing_fn evaluate_call <Anonymous> evaluate in_dir in_input_dir eng_r block_exec call_block process_group.block process_group withCallingHandlers process_file <Anonymous> <Anonymous> execute .main \n[1] \"<0x11a620648>\"\n[1] \"<0x11a620648>\"\n```\n:::\n:::\n\n\n\n::: {.notes}\nmakes copy for each separate block of code\ne.g. if run with above in one go interactively no copies\n     if run in separate chunks 1 copy  \n:::\n     \n\n\n# Benchmarking {.inverse}\n\n## Benchmarking\n\nThere will usually be many ways to write code for a given task. To compare\nalternatives, we can use benchmark the code.\n\nIf the code is more than a single expression, create wrappers for each alternative\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngrow <- function(n){\n  res <- NULL\n  for (i in 1:n) res <- c(res, 1)\n  res\n}\npre_specify <- function(n){\n  res <- numeric(n)\n  for (i in seq_along(res)) res[i] <- 1\n  res\n}\n```\n:::\n\n\n## `bench::mark()`\n\nRun the two alternatives with `bench::mark()`. This function \n\n - Runs alternatives &ge; 1 time; at most enough times to take 0.5s\n - Makes sure the two expressions return the same result!  \n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(bench)\n(bm <- bench::mark(grow(5000), pre_specify(5000)))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  expression             min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr>        <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 grow(5000)          26.1ms   30.1ms      32.7    95.6MB    59.6 \n2 pre_specify(5000)   98.9µs  107.9µs    9036.     55.8KB     6.00\n```\n:::\n:::\n\n\n* `GC` is the garbage collector which tidies up deleted objects\n* `itr/sec` is how many times the expression could be run in 1s\n\n## Plotting benchmarks\n\nDistribution tends to be right-skewed - focus on the median!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(bm)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-2-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\n## Scaling\n\nBenchmarking can be difficult as the best option can depend on the size of the data, e.g. memory allocation can overshadow run time for small objects.\n\nWhen thinking about how our code scales to bigger, we need to consider what we mean by \"big\"\n\n - number of rows or number of columns?\n - number of observations or number of factor levels?\n \n `bench::press()` compares a function over a grid of parameters \n\n## `bench::press()`\n\n::: {.smaller90}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbench::press(n = c(10, 100), k = c(10, 1),\n  bench::mark(gl(n, k, length = 1000)) # `gl` generates factor levels\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRunning with:\n      n     k\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n1    10    10\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n2   100    10\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n3    10     1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n4   100     1\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 8\n  expression                 n     k    min  median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr>             <dbl> <dbl> <bch:> <bch:t>     <dbl> <bch:byt>    <dbl>\n1 gl(n, k, length = 100…    10    10 3.12µs  3.61µs   244789.    12.4KB     24.5\n2 gl(n, k, length = 100…   100    10 9.47µs 10.25µs    94884.   11.05KB     19.0\n3 gl(n, k, length = 100…    10     1 2.79µs   3.2µs   300082.    3.95KB     30.0\n4 gl(n, k, length = 100…   100     1  6.4µs  7.09µs   135881.    7.53KB     13.6\n```\n:::\n:::\n\n:::\n\n## Exercise 1\n\nSuppose we have a matrix of data and a two-level factor\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnr <- 10\nnc <- 50\nX <- matrix(rnorm(nr * nc, 10, 3), nrow = nr)\ngrp <- gl(2, nc/2)\n```\n:::\n\n\nUse `bench::mark()` to compare the following ways to find the coefficients of a linear model fitted to each row\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# one\nres <- vector(\"list\", nr)\nfor(i in seq_len(nr)){\n  res[[i]] <- coef(lm(X[i,] ~ grp))\n}\ndo.call(\"cbind\", res)\n# two\nres2 <- coef(lm(t(X) ~ grp))\n```\n:::\n\n\n\n# Improving run time {.inverse}\n\n## Faster common operations\n\n* Sorting\n  - Use `sort(x, partial = 1:10)` to get the top 10\n  - Use `sort(x, decreasing = TRUE)` vs `rev(sort(x))`\n\n. . .\n\n* Generating numeric vectors\n  - `seq.int()`, `seq_along(x)`, `seq_len(n)` vs `seq()`    \n  - `rep.int()` or `rep_len(n)` vs `rep()` \n\n. . .\n\n* `which.min()`, `which.max()` vs e.g. `which(x == min(x))`\n\n. . .\n\n* `anyNA(x)` vs `any(is.na(x))`\n\n\n::: {.notes}\n\"int\" stands for internal!\n:::\n\n## For loops\n\nFor loops are an intuitive way to write code, but can be very inefficient. \n\n`for` is a function, `:` or `seq_along` is another\nfunction, each use of `[` is a call to a function, ..., so a loop\ninvolves many nested function calls.\n\n. . .\n\nTry to keep for loops for truly iterative computations or tasks that are fast\nin any case (optimizing code takes time!)\n\nOtherwise make loops as lean as possible, by pre-computing values that do not need be be computed iteratively.\n\n## Vectorization\n\nVectorization is operating on vectors (or vector-like objects) rather than individual elements.\n\nMany operations in R are vectorized, e.g.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- 1:3\ny <- 3:1\nx == y\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE  TRUE FALSE\n```\n:::\n\n```{.r .cell-code}\nlog(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0000000 0.6931472 1.0986123\n```\n:::\n\n```{.r .cell-code}\nres <- list(a = 1:3, b = 1:6)\nlengths(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\na b \n3 6 \n```\n:::\n:::\n\n\nWe do not need to loop through each element!\n\n## Recycling\n\nVectorized functions will recycle shorter vectors to create vectors of \nthe same length\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n1:4 + 0:1 + 2 # 1+0+2, 2+1+2, 3+0+2, 4+1+2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3 5 5 7\n```\n:::\n:::\n\nThis is particularly useful for single values\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncbind(1, 3:4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2]\n[1,]    1    3\n[2,]    1    4\n```\n:::\n:::\n\nand for generating regular patterns\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npaste0(rep(1:3, each = 2), c(\"a\", \"b\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"1a\" \"1b\" \"2a\" \"2b\" \"3a\" \"3b\"\n```\n:::\n:::\n\n\n## `ifelse()`\n\n`ifelse` is a vectorised version of `if` and `else` blocks\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- c(5, 2, 9, 12)\nifelse(x > 6, 2 * x, 3 * x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 15  6 18 24\n```\n:::\n:::\n\n\nRecycling is also very useful here\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- 1:10\nifelse(x %% 2 == 0, 5, 12)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 12  5 12  5 12  5 12  5 12  5\n```\n:::\n:::\n\n\nHowever indexing is more efficient than `ifelse`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ny <- rep.int(12, 10)\ny[x %% 2 == 0] <- 5\ny\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 12  5 12  5 12  5 12  5 12  5\n```\n:::\n:::\n\n\n## Logical operations\n\nLogical operators such as `&` and `|` are vectorized, e.g.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- c(1, 0.6, 1.2, 0.4, 0.5)\nx > 0.4 & x < 0.8\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE  TRUE FALSE FALSE  TRUE\n```\n:::\n:::\n\n\nIf we only want to compare vectors of length 1 the operators `&&` and `||` are more efficient as they only compute the RHS if needed\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx[1] > 0.4 && x[1] < 0.8\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n:::\n\n\nMake sure the vectors are of length 1, otherwise you get an error. This change was introduced in R &ge; 4.3. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx > 0.4 && x < 0.8\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in x > 0.4 && x < 0.8: 'length = 5' in coercion to 'logical(1)'\n```\n:::\n:::\n\n\n::: {.notes}\nIn R &ge 4.2.0 you get a warning but it still returns a comparison of only the first element. In earlier versions, there was no warning.  \n:::\n\n## Vectorization and Matrices\n\nVectorizations applies to matices too, not only through matrix algebra\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nM <- matrix(1:4, nrow = 2, ncol = 2)\nM + M\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2]\n[1,]    2    6\n[2,]    4    8\n```\n:::\n:::\n\nbut also vectorized functions\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nM <- M + rep(1.3, 4)\nround(M)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2]\n[1,]    2    4\n[2,]    3    5\n```\n:::\n:::\n\n\n## Matrices and Recycling\n\nValues are recycled down matrix, which is convenient for \nrow-wise operations\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nM <- matrix(1:6, nrow = 2, ncol = 3)\nM\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n```\n:::\n\n```{.r .cell-code}\nM - 1:2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2] [,3]\n[1,]    0    2    4\n[2,]    0    2    4\n```\n:::\n:::\n\nTo do the same for columns we would need to explicitly replicate, \nwhich is not so efficient.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nM - rep(1:3, each = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2] [,3]\n[1,]    0    1    2\n[2,]    1    2    3\n```\n:::\n:::\n\n\n## Row/Column-wise Operations\n\nSeveral functions are available implementing efficient row/column-wise\noperations, e.g. `colMeans()`, `rowMeans()`, `colSums()`, `rowSums()`, `sweep()`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nM <- matrix(1:4, nrow = 2, ncol = 2)\nrowMeans(M)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2 3\n```\n:::\n:::\n\n\nThese provide an alternative to iterating though rows and columns in R (the \niteration happens in C, which is faster).\n\nThe **matrixStats** provides further \"matricised\" methods, including medians and standard deviations.\n\n## Exercise 2 (h/t Raju Bhakta)\n\nSampling from 0.3 × N(0, 1) + 0.5 × N(10, 1) + 0.2 × N(3, 0.1):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Set the random seed and the number of values to sample\nset.seed(1); n <- 100000                 \n\n# Sample the component each value belongs to\ncomponent <- sample(1:3, prob = c(0.3, 0.5, 0.2), \n                    size = n, replace = TRUE)\n\n# Sample from the corresponding Normal for each value\nx <- numeric(n)\nfor(i in seq_len(n)){\n  if (component[i] == 1){\n    x[i] <- rnorm(1, 0, 1)\n  } else if (component[i] == 2) {\n    x[i] <- rnorm(1, 10, 1)\n  } else {\n    x[i] <- rnorm(1, 3, sqrt(0.1))\n  }\n}\n```\n:::\n\n\n## Exercise 2 (continued)\n\nThe for loop in the previous code is suitable for vectorization: the iterations are completely independent.\n\n`rnorm()` is vectorized in the arguments `mu` and `sd`, e.g. to simulate a value from the 1st and 3rd component we could write:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmu <- c(0, 10, 3)\nsd <- sqrt(c(1, 1, 0.1))\nrnorm(2, mu[c(1, 3)], sd[c(1, 3)])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6528158 2.7948388\n```\n:::\n:::\n\n\nUse this information to replace the for loop, using a single call to `rnorm()` to simulate `n` values from the mixture distribution.\n\nUse `bench::mark()` to compare the two approaches - don't forget to set the same seed so the simulations are equivalent!\n\n\n\n\n# End Matter {.inverse}\n\n## Resources\n\nMaterial inspired by and remixed from:\n\n- \n\n## License\n\nLicensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License ([CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/){target=\"_blank\"}).\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}