{
  "hash": "f262f1af829f1c71baa016d757b061df",
  "result": {
    "markdown": "---\ntitle: Efficient Programming\nsubtitle: Advanced R\nauthor: \n  - name: Heather Turner and Ella Kaye\n  - name: Department of Statistics, University of Warwick\ntitle-slide-attributes:\n  data-background-color: \"#552D62\"\ndate: 2023-06-19\ndate-format: long\nformat: \n  warwickpres-revealjs:\n    execute:\n      echo: true\n      code-overflow: wrap\n---\n\n\n## Overview\n\n- Memory management\n- Benchmarking\n- Improving run time\n- Parallelisation\n- Outlook to package development\n\n# Memory management {.inverse}\n\n## Overview\n\nObjects created in R are stored in memory. This has the advantage that\nobjects can be accessed faster, but R slows down as the memory fills up.\nCreating objects also takes time. \n\nTherefore:\n\n::: {.incremental}\n- Re-use temporary variables. The allocated storage will be re-used if\nthe vector has the same length.\n- Save results for re-use, e.g. index variables\n- Don't save intermediate results unnecessarily -- compute on-the-fly\n- Remove large objects when no longer needed (with `rm()`)\n:::\n\n## Basic data structures\n\nTry to use the simplest data structure for your purpose\n\n - matrices vs. data frames \n - character or integer vectors vs. factors\n - logical or integer vectors vs. numeric vectors\n - unnamed objects vs. named objects\n\n. . .\n\nIt is especially important to use low-level structures for computation\n\nYou can create richer objects as a final step before returning to the user.\n\n::: {.notes}\nL for integer\n:::\n\n## Big Data\n\nModern computers have enough RAM to work with millions of records \nusing standard functions.\n\nSome packages to work more efficiently with big data:\n\n - **data.table** faster operations on data frames; read/write \nlarge CSVs\n - **dplyr** + **dbplyr** processing of data in databases.\n - **arrow** read/write large CSVs or binary files e.g. Parquet; processing larger-than-memory data with **dplyr** commands.\n - **bigmemory**, **biganalytics** faster matrix operations,\ngeneralized linear models, kmeans\n\n::: {.notes}\nN.B. sparse matrices not as efficient as you might expect for general programming, may need big data for it to be important.\n\nParallelisation can also help, see later\n:::\n\n## Growing Objects\n\nAdding to an object in a loop\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nres <- NULL\nfor (i in 1:5000) res <- c(res, 1)\n```\n:::\n\n   \nmay force a copy to be made at each iteration, with each copy stored until the\nloop has completed. \n\n. . .\n\nIt is **far better** to create an object of the necessary size first  \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nres <- numeric(5000)\nfor (i in seq_along(res)) res[i] <- 1\n```\n:::\n\n\nTo initialise a list we can use\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nres <- vector(mode = \"list\", length = 100)\n```\n:::\n\n\n## Copy-on-Change\n\nR usually copies an object to make changes to it.\n\n`tracemem` can be used to trace copies of an object\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nz <- NULL\nfor (i in 1:3){ z <- c(z,1); print(tracemem(z)) }\n```\n:::\n\n```\n[1] \"<0x122220648>\"\n[1] \"<0x11940ba08>\"\n[1] \"<0x127b9b9c8>\"\n```\n\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nz <- numeric(2); print(tracemem(z))\n```\n:::\n\n```\n[1] \"<0x1193ce2c8>\"\n```\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfor (i in 1:2){ z[i] <- i;print(tracemem(z)) }\n```\n:::\n\n```\ntracemem[0x1193ce2c8 -> 0x135159648]: \n[1] \"<0x135159648>\"\n[1] \"<0x135159648>\"\n```\n\n\n::: {.notes}\nmakes copy for each separate block of code\ne.g. if run with above in one go interactively no copies\n     if run in separate chunks 1 copy  \n:::\n     \n\n\n# Benchmarking {.inverse}\n\n## Benchmarking\n\nThere will usually be many ways to write code for a given task. To compare\nalternatives, we can use benchmark the code.\n\nIf the code is more than a single expression, create wrappers for each alternative\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngrow <- function(n){\n  res <- NULL\n  for (i in 1:n) res <- c(res, 1)\n  res\n}\npre_specify <- function(n){\n  res <- numeric(n)\n  for (i in seq_along(res)) res[i] <- 1\n  res\n}\n```\n:::\n\n\n## `bench::mark()`\n\nRun the two alternatives with `bench::mark()`. This function \n\n - Runs alternatives &ge; 1 time; at most enough times to take 0.5s\n - Makes sure the two expressions return the same result!  \n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(bench)\n(bm <- bench::mark(grow(5000), pre_specify(5000)))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  expression             min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr>        <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 grow(5000)          33.9ms   36.8ms      26.7    95.6MB    49.6 \n2 pre_specify(5000)  130.2µs  133.4µs    7274.     55.8KB     4.00\n```\n:::\n:::\n\n\n* `GC` is the garbage collector which tidies up deleted objects\n* `itr/sec` is how many times the expression could be run in 1s\n\n## Plotting benchmarks\n\nDistribution tends to be right-skewed - focus on the median!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(bm)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-2-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\n## Scaling\n\nBenchmarking can be difficult as the best option can depend on the size of the data, e.g. memory allocation can overshadow run time for small objects.\n\nWhen thinking about how our code scales to bigger, we need to consider what we mean by \"big\"\n\n - number of rows or number of columns?\n - number of observations or number of factor levels?\n \n `bench::press()` compares a function over a grid of parameters \n\n## `bench::press()`\n\n::: {.smaller90}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbench::press(n = c(10, 100), k = c(10, 1),\n  bench::mark(gl(n, k, length = 1000)) # `gl` generates factor levels\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRunning with:\n      n     k\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n1    10    10\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n2   100    10\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n3    10     1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n4   100     1\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 8\n  expression                n     k     min  median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr>            <dbl> <dbl> <bch:t> <bch:t>     <dbl> <bch:byt>    <dbl>\n1 gl(n, k, length = 10…    10    10   4.1µs  4.55µs   195039.    12.4KB     19.5\n2 gl(n, k, length = 10…   100    10 11.64µs 12.22µs    79852.   11.05KB     16.0\n3 gl(n, k, length = 10…    10     1  3.65µs  3.98µs   244481.    3.95KB     24.5\n4 gl(n, k, length = 10…   100     1  7.71µs  8.24µs   116566.    7.53KB     23.3\n```\n:::\n:::\n\n:::\n\n## Exercise 1\n\nSuppose we have a matrix of data and a two-level factor\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnr <- 10\nnc <- 50\nX <- matrix(rnorm(nr * nc, 10, 3), nrow = nr)\ngrp <- gl(2, nc/2)\n```\n:::\n\n\nUse `bench::mark()` to compare the following ways to find the coefficients of a linear model fitted to each row\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# one\nres <- vector(\"list\", nr)\nfor(i in seq_len(nr)){\n  res[[i]] <- coef(lm(X[i,] ~ grp))\n}\ndo.call(\"cbind\", res)\n# two\nres2 <- coef(lm(t(X) ~ grp))\n```\n:::\n\n\n\n# Improving run time {.inverse}\n\n## Faster common operations\n\n* Sorting\n  - Use `sort(x, partial = 1:10)` to get the top 10\n  - Use `sort(x, decreasing = TRUE)` vs `rev(sort(x))`\n\n. . .\n\n* Generating numeric vectors\n  - `seq.int()`, `seq_along(x)`, `seq_len(n)` vs `seq()`    \n  - `rep.int()` or `rep_len(n)` vs `rep()` \n\n. . .\n\n* `which.min()`, `which.max()` vs e.g. `which(x == min(x))`\n\n. . .\n\n* `anyNA(x)` vs `any(is.na(x))`\n\n\n::: {.notes}\n\"int\" stands for internal!\n:::\n\n## For loops\n\nFor loops are an intuitive way to write code, but can be very inefficient. \n\n`for` is a function, `:` or `seq_along` is another\nfunction, each use of `[` is a call to a function, ..., so a loop\ninvolves many nested function calls.\n\n. . .\n\nTry to keep for loops for truly iterative computations or tasks that are fast\nin any case (optimizing code takes time!)\n\nOtherwise make loops as lean as possible, by pre-computing values that do not need be be computed iteratively.\n\n## Vectorization\n\nVectorization is operating on vectors (or vector-like objects) rather than individual elements.\n\nMany operations in R are vectorized, e.g.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- 1:3\ny <- 3:1\nx == y\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE  TRUE FALSE\n```\n:::\n\n```{.r .cell-code}\nlog(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0000000 0.6931472 1.0986123\n```\n:::\n\n```{.r .cell-code}\nres <- list(a = 1:3, b = 1:6)\nlengths(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\na b \n3 6 \n```\n:::\n:::\n\n\nWe do not need to loop through each element!\n\n## Recycling\n\nVectorized functions will recycle shorter vectors to create vectors of \nthe same length\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n1:4 + 0:1 + 2 # 1+0+2, 2+1+2, 3+0+2, 4+1+2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3 5 5 7\n```\n:::\n:::\n\nThis is particularly useful for single values\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncbind(1, 3:4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2]\n[1,]    1    3\n[2,]    1    4\n```\n:::\n:::\n\nand for generating regular patterns\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npaste0(rep(1:3, each = 2), c(\"a\", \"b\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"1a\" \"1b\" \"2a\" \"2b\" \"3a\" \"3b\"\n```\n:::\n:::\n\n\n## `ifelse()`\n\n`ifelse` is a vectorised version of `if` and `else` blocks\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- c(5, 2, 9, 12)\nifelse(x > 6, 2 * x, 3 * x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 15  6 18 24\n```\n:::\n:::\n\n\nRecycling is also very useful here\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- 1:10\nifelse(x %% 2 == 0, 5, 12)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 12  5 12  5 12  5 12  5 12  5\n```\n:::\n:::\n\n\nHowever indexing is more efficient than `ifelse`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ny <- rep.int(12, 10)\ny[x %% 2 == 0] <- 5\ny\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 12  5 12  5 12  5 12  5 12  5\n```\n:::\n:::\n\n\n## Logical operations\n\nLogical operators such as `&` and `|` are vectorized, e.g.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- c(1, 0.6, 1.2, 0.4, 0.5)\nx > 0.4 & x < 0.8\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE  TRUE FALSE FALSE  TRUE\n```\n:::\n:::\n\n\nIf we only want to compare vectors of length 1 the operators `&&` and `||` are more efficient as they only compute the RHS if needed\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx[1] > 0.4 && x[1] < 0.8\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n:::\n\n\nMake sure the vectors are of length 1, otherwise you get an error. This change was introduced in R &ge; 4.3. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx > 0.4 && x < 0.8\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in x > 0.4 && x < 0.8: 'length = 5' in coercion to 'logical(1)'\n```\n:::\n:::\n\n\n::: {.notes}\nIn R &ge 4.2.0 you get a warning but it still returns a comparison of only the first element. In earlier versions, there was no warning.  \n:::\n\n## Vectorization and Matrices\n\nVectorizations applies to matices too, not only through matrix algebra\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nM <- matrix(1:4, nrow = 2, ncol = 2)\nM + M\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2]\n[1,]    2    6\n[2,]    4    8\n```\n:::\n:::\n\nbut also vectorized functions\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nM <- M + rep(1.3, 4)\nround(M)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2]\n[1,]    2    4\n[2,]    3    5\n```\n:::\n:::\n\n\n## Matrices and recycling: rows\n\nValues are recycled down matrix, which is convenient for \nrow-wise operations\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nM <- matrix(1:6, nrow = 2, ncol = 3)\nM\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n```\n:::\n\n```{.r .cell-code}\nM - 1:2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2] [,3]\n[1,]    0    2    4\n[2,]    0    2    4\n```\n:::\n:::\n\n\n## Matrices and recycling: columns\n\nTo do the same for columns we would need to explicitly replicate, \nwhich is not so efficient.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nM - rep(1:3, each = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2] [,3]\n[1,]    0    1    2\n[2,]    1    2    3\n```\n:::\n:::\n\n\n## `apply()`\n\n`apply` provides a way to apply a function to every row or column of a matrix\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nM <- matrix(1:20, 2, 10)\nM\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    1    3    5    7    9   11   13   15   17    19\n[2,]    2    4    6    8   10   12   14   16   18    20\n```\n:::\n\n```{.r .cell-code}\n# MARGIN 1 over rows\napply(M, 1, quantile, 0.75)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 14.5 15.5\n```\n:::\n\n```{.r .cell-code}\n# MARGIN 2 over columns\napply(M, 2, mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  1.5  3.5  5.5  7.5  9.5 11.5 13.5 15.5 17.5 19.5\n```\n:::\n:::\n\n\n## `lapply()`\n\n`lapply` applies a given function to each element of a list\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nl <- list()\nl$x <- 1:3\nl$y <- 4:6\nlapply(l, mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$x\n[1] 2\n\n$y\n[1] 5\n```\n:::\n:::\n\n\n## `sapply()` and `vapply()`\n\n`sapply` acts similarly to `lapply`, but tries to simplify the result\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsapply(l, mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nx y \n2 5 \n```\n:::\n:::\n\n\nIt is better to use `vapply()` in programming as it ensures the returned object is of the expected type (and is slightly faster)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvapply(l, mean, numeric(1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nx y \n2 5 \n```\n:::\n:::\n\n\n## Row/Column-wise Operations\n\nSeveral functions are available implementing efficient row/column-wise\noperations, e.g. `colMeans()`, `rowMeans()`, `colSums()`, `rowSums()`, `sweep()`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nM <- matrix(1:4, nrow = 2, ncol = 2)\nrowMeans(M)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2 3\n```\n:::\n:::\n\n\nThese provide an alternative to iterating though rows and columns in R (the \niteration happens in C, which is faster).\n\nThe **matrixStats** provides further \"matricised\" methods, including medians and standard deviations.\n\n## Exercise 2 (h/t Raju Bhakta)\n\nSampling from 0.3 × N(0, 1) + 0.5 × N(10, 1) + 0.2 × N(3, 0.1):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Set the random seed and the number of values to sample\nset.seed(1); n <- 100000                 \n\n# Sample the component each value belongs to\ncomponent <- sample(1:3, prob = c(0.3, 0.5, 0.2), \n                    size = n, replace = TRUE)\n\n# Sample from the corresponding Normal for each value\nx <- numeric(n)\nfor(i in seq_len(n)){\n  if (component[i] == 1){\n    x[i] <- rnorm(1, 0, 1)\n  } else if (component[i] == 2) {\n    x[i] <- rnorm(1, 10, 1)\n  } else {\n    x[i] <- rnorm(1, 3, sqrt(0.1))\n  }\n}\n```\n:::\n\n\n## Exercise 2 (continued)\n\nThe for loop in the previous code is suitable for vectorization: the iterations are completely independent.\n\n`rnorm()` is vectorized in the arguments `mu` and `sd`, e.g. to simulate a value from the 1st and 3rd component we could write:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmu <- c(0, 10, 3)\nsd <- sqrt(c(1, 1, 0.1))\nrnorm(2, mu[c(1, 3)], sd[c(1, 3)])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.3283113  3.3153085\n```\n:::\n:::\n\n\nUse this information to replace the for loop, using a single call to `rnorm()` to simulate `n` values from the mixture distribution.\n\nUse `bench::mark()` to compare the two approaches - don't forget to set the same seed so the simulations are equivalent!\n\n# Parallelisation {.inverse}\n\n## Parallelisation\n\nMost functions in R run on a single core of your machine. The \n**future.apply** package, part of the futureverse, provides \nparallel versions of all the `apply`-type functions.\n\n<https://www.futureverse.org>\n\nParallelisation is most straight-forward to implement for\n*embarrassingly parallel* problems, such as applying a function to\nelements of a list.\n\n## Example setup\n\n[Adapted from <https://henrikbengtsson.github.io/course-stanford-futureverse-2023/>]{.smaller75}\n\nLet's create a slow function:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nslow_sum <- function(x) {\n  sum <- 0\n  \n  for (value in x) {\n    Sys.sleep(0.5)  ## half-second slowdown per value\n    sum <- sum + value\n  }\n  \n  sum\n}\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='index_cache/revealjs/unnamed-chunk-21_47c56b9e13a277b6f497a104fef2450e'}\n\n```{.r .cell-code}\nlibrary(tictoc)\ntic()\ny <- slow_sum(1:10)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n5.032 sec elapsed\n```\n:::\n:::\n\n\n## Parallelising map-reduce calls\n\nNow suppose we have four sets of numeric vectors, in a list, and we want to calculate `slow_sum()` for each:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nxs <- list(1:10, 11:20, 21:30, 31:40)\n```\n:::\n\n\nWe *could* run `lapply()` over this, but it takes a while as it handles each list item in turn:\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/revealjs/unnamed-chunk-23_55345fffd3234e5f020701ea07e79b53'}\n\n```{.r .cell-code}\ntic()\nys <- lapply(xs, slow_sum)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n20.139 sec elapsed\n```\n:::\n:::\n\n\n## Setting up for parallel processing\n\nThe **future.apply** package comes to the rescue! \n\nThe first step is to make a cluster from the available cores.\n\nTo parallelise on a local machine, use `multisession` in `plan()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(future.apply)\nplan(multisession)\n```\n:::\n\n\nThe default number of workers is `availableCores()`.\n\nWe'll also use the **tictoc** package for timings:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tictoc)\n```\n:::\n\n\n\n## Using `future_lapply()`\n\n`future_lapply()` is a drop-in parallel replacement for `lapply()`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplan(multisession, workers = 4)\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='index_cache/revealjs/unnamed-chunk-26_6331c970076ee28fd68bcac3d749ece8'}\n\n```{.r .cell-code}\ntic()\nys <- future_lapply(xs, slow_sum)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n5.266 sec elapsed\n```\n:::\n:::\n\n\nThe four slow sums are calculated in about the same time as it takes to calculate one, since they are being calculated simultaneously on separate cores.\n\n## Your turn!\n\nThe **efficient** package contains a function to simulate a game of snakes and \nladders, returning the number of rolls required to win.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nremotes::install_github(\"csgillespie/efficient\",\n                         INSTALL_opts = \"--with-keep.source\")\n```\n:::\n\n\nParallelise the following code:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(efficient)\nN <- 100\nnrolls <- sapply(seq_len(N), snakes_ladders)\n```\n:::\n\n\nUse **tictoc** to compare the run-times. Roughly large does `N` have to be for the parallel version to be worth using?\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n::: {.notes}\n\"--with-keep.source\" as this is needed for profiling in next session\n:::\n\n## General Principles\n\n- Try to use vectorized functions where possible.\n\n- Otherwise use the `apply` family (and parellelise if necessary). Custom\nfunctions will often be useful here to pass to `apply` etc.\n\n- Try to keep for loops for true iterative computations or tasks that are fast\nin any case (optimizing code takes time!)\n\n# End matter {.inverse}\n\n## References\n\nGood references on optimizing R code:\n\n- Wickham, H, _Advanced R_ (2nd edn), _Improving performance section_, <https://adv-r.hadley.nz/perf-improve.html>\n\n- Gillespie, C and Lovelace, R, _Efficient R programming_, <https://csgillespie.github.io/efficientR/>\n\nTutorials on the Futureverse:\n\n- <https://www.futureverse.org/tutorials.html>\n\n## License\n\nLicensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License ([CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/){target=\"_blank\"}).\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}